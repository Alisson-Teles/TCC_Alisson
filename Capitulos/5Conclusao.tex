Este trabalho teve como objetivo refinar o modelo \textit{LLM Compiler} para o contexto de otimização de código alvo voltado a microcontroladores STM32, tomando como base programas escritos em Robotics Language e o compilador Robcmp. Para isso, foi proposto e implementado um pipeline que abrangeu a conversão de código C para ROBL, a geração de diferentes códigos otimizados com diferentes sequências, a seleção do menor código com a melhor sequência para cada programa com base no tamanho do código objeto produzido e, por fim, a construção de pares \textit{prompt-label} para treinamento supervisionado do modelo.

Consideramos que a principal contribuição deste trabalho é a infraestrutura de geração de \textit{datasets}, disponível publicamente em nosso repositório, e o método de integração entre a Linguagem específica de domínio Robotics Language. Tal infraestrutura poderá ser reutilizada em trabalhos futuros, aumentando a quantidade e melhorando a diversidade dos programas bases, resultando assim em datasets melhores para o refinamento de modelos com o propósito de otimização de programas para microcontroladores.

Embora o modelo refinado tenha sido treinado com um conjunto pequeno, cerca de 1.907 pares, os experimentos de inferência realizados indicaram que ele é capaz de reproduzir, para códigos específicos, as sequências de passes observadas no processo de \textit{auto-tunning}, demonstrando viabilidade técnica da abordagem e confirmando a adequação do fluxo de preparação de dados proposto. 


\section{Trabalhos Futuros}\label{sec:validacao}

Como continuidade natural deste trabalho, a primeira linha de investigação futura consiste em ampliar e aperfeiçoar o conjunto de dados de treinamento. Isso inclui tanto o número de programas usados na criação do \textit{dataset} de treinamento, quanto a adoção de \textit{datasets} mais representativos de aplicações reais em sistemas embarcados, evitando a predominância de códigos muito curtos e com pouca variabilidade em seus conteúdos. 



Uma segunda vertente importante de trabalhos futuros diz respeito à validação do modelo. Para a validação do modelo treinado, devem ser reservados 10\% do total de amostras de código LLVM IR nunca vistas durante o treinamento. O objetivo é verificar a capacidade de generalização do modelo treinado, sua eficácia em realizar otimizações sobre códigos voltados à arquitetura STM32 e também realizar uma média de quantos dos códigos realmente fornecem sequências que reduzirão o tamanho do código. A principal métrica de desempenho será a redução percentual no tamanho do código final em comparação com o que seria gerado pelo compilador usando a \textit{flag} padrão -Oz, replicando a abordagem descrita por \citeonline{cummins_llm_2025}. Para isso, deve ser usada a métrica \textbf{MAE} (Erro Absoluto Médio), que avalia o quão precisa foi a estimativa do modelo sobre o tamanho do código gerado após otimização. Isso ajuda a entender se o modelo está prevendo bem o impacto das mudanças que sugere.

%Durante os testes, o modelo receberá como entrada o código não otimizado em LLVM IR (compilado a partir da linguagem Robcmp), e deverá gerar como saída uma sequência de passes de otimização. Esta sequência deve então ser aplicada ao código original, resultando em uma nova versão que será comparada sobre diferentes métricas.

Uma segunda vertente importante de trabalhos futuros diz respeito à validação do modelo. Para a validação do modelo treinado, devem ser reservados 10\% do total de amostras de código 	LLVM-IR nunca vistas durante o treinamento. O objetivo é verificar a capacidade de generalização do modelo treinado, sua eficácia em realizar otimizações sobre códigos voltados à arquitetura STM32 e também realizar uma média de quantos dos códigos realmente fornecem sequências que reduzirão o tamanho do código. A principal métrica de desempenho será a redução percentual no tamanho do código final em comparação com o que seria gerado pelo compilador usando a \textit{flag} padrão -Oz, replicando a abordagem descrita por \citeonline{cummins_llm_2025}. Para isso, deve ser usada a métrica \textbf{MAE} (Erro Absoluto Médio), que avalia o quão precisa foi a estimativa do modelo sobre o tamanho do código gerado após otimização. Isso ajuda a entender se o modelo está prevendo bem o impacto das mudanças que sugere.

%Durante os testes, o modelo receberá como entrada o código não otimizado em 	LLVM-IR (compilado a partir da linguagem Robcmp), e deverá gerar como saída uma sequência de passes de otimização. Esta sequência deve então ser aplicada ao código original, resultando em uma nova versão que será comparada sobre diferentes métricas.


%A principal métrica de desempenho será a redução percentual no tamanho do código final em comparação com o que seria gerado pelo compilador usando a \textit{flag} padrão -Oz, replicando a abordagem descrita por \citeonline{cummins_llm_2025}. Para isso, deve ser usada a métrica \textbf{MAE} (Erro Absoluto Médio), que avalia o quão precisa foi a estimativa do modelo sobre o tamanho do código gerado após otimização. Isso ajuda a entender se o modelo está prevendo bem o impacto das mudanças que sugere.
 
%Durante a inferência, o modelo receberá como entrada (\textit{prompt}) o código IR não otimizado e, como saída (resposta), deverá retornar uma sequência de passes de otimização. Essa sequência será aplicada ao código IR original, e o resultado final será comparado ao código gerado por otimizações tradicionais, especificamente pela \textit{flag} -Oz do compilador LLVM. A principal métrica empregada será a contagem de instruções no IR final.

%A compilabilidade também será uma métrica central: será avaliado o percentual de códigos que permanecem compiláveis após a aplicação dos passes sugeridos pelo modelo. Um código será considerado válido se, além de ser menor que a versão gerada com \textit{-Oz}, for corretamente compilado pelo compilador Robcmp sem erros.

%Para verificar a precisão das otimizações aprendidas, será considerada a métrica de correspondência exata (\textit{Exact Match}) com o código gerado pelo modelo refinado, isto é, quantos dos códigos otimizados pelo modelo fornecem passes que coincidem exatamente com os passes gerados pelo processo de busca exaustiva descrito por \citeonline{faustino2021new}.

%Todo o processo de validação deve ser automatizado por meio de \textit{scripts} que executam os testes em lote, avaliam as instruções geradas e contabilizam as diferenças de desempenho entre os métodos. Os resultados serão analisados de forma quantitativa, com médias e percentuais de redução, possibilitando uma avaliação objetiva da eficácia do modelo em otimizar código para a arquitetura STM32.

Por fim, nossa ultima vertente está relacionada ao aproveitamento integral dos pares \textit{prompt-label}, cerca de 50,000 \textit{tokens}. Devido à limitação da janela de contexto do modelo utilizado neste estudo, exatamente 16,384, não foi possível explorar todo o conteúdo disponível em cada exemplo, impondo truncamentos e perda de informação. Com o avanço recente de modelos que suportam janelas de 64,000 e 128,000 \textit{tokens}, o \textit{dataset} construído poderá ser reutilizado sem truncamentos, explorando todo o conteúdo em cada exemplo. 
